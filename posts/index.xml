<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>Posts on Shubham Utwal</title>
		<link>https://shubhamutwal.in/posts/</link>
		<description>Recent content in Posts on Shubham Utwal</description>
		<generator>Hugo -- gohugo.io</generator>
		<language>en-us</language>
		<copyright>&amp;copy; &lt;a href=&#34;https://shubhamutwal.in&#34;&gt;Shubham Utwal&lt;/a&gt; 2021</copyright>
		<lastBuildDate>Sat, 29 Jan 2022 18:40:02 +0530</lastBuildDate>
		<atom:link href="https://shubhamutwal.in/posts/index.xml" rel="self" type="application/rss+xml" />
		
		<item>
			<title>Using CompletableFuture for parallelism, and variants of ThreadPoolExecutors</title>
			<link>https://shubhamutwal.in/posts/parallelism-in-java/</link>
			<pubDate>Sat, 29 Jan 2022 18:40:02 +0530</pubDate>
			
			<guid>https://shubhamutwal.in/posts/parallelism-in-java/</guid>
			<description>Completable Futures &amp;amp; ForkJoinPool CompletableFutures prove useful in areas where one has to perform multiple tasks in a parallel manner, probably wait on them and combine the results.
By default, the CompletableFuture implementation makes use of the commonPool provided by the ForkJoinPool framework. The distinguishing thing between other ThreadPoolExecutors &amp;amp; ForkJoinPool is the workStealing implementation.
Quoting the docs -
 all threads in the pool attempt to find and execute tasks submitted to the pool and/or created by other active tasks (eventually blocking waiting for work if none exist).</description>
			<content type="html"><![CDATA[<h2 id="completable-futures--forkjoinpool">Completable Futures &amp; ForkJoinPool</h2>
<p>CompletableFutures prove useful in areas where one has to perform multiple tasks in a parallel manner, probably wait on them and combine the results.</p>
<p>By default, the CompletableFuture implementation makes use of the commonPool provided by the ForkJoinPool framework. The distinguishing thing between other ThreadPoolExecutors &amp; ForkJoinPool is the workStealing implementation.</p>
<p>Quoting the docs -</p>
<blockquote>
<p>all threads in the pool attempt to find and execute tasks submitted to the pool and/or created by other active tasks (eventually blocking waiting for work if none exist). This enables efficient processing when most tasks spawn other subtasks (as do most ForkJoinTasks), as well as when many small tasks are submitted to the pool from external clients. Using the common pool normally reduces resource usage (its threads are slowly reclaimed during periods of non-use, and reinstated upon subsequent use).</p>
</blockquote>
<p>The pool is preferable for a use case that is non-blocking in nature.</p>
<p>Quoting the docs again -</p>
<blockquote>
<p>a ForkJoinPool may be constructed with a given target parallelism level; by default, equal to the number of available processors. The pool attempts to maintain enough active (or available) threads by dynamically adding, suspending, or resuming internal worker threads, even if some tasks are stalled waiting to join others. However, no such adjustments are guaranteed in the face of blocked I/O or other unmanaged synchronization.</p>
</blockquote>
<p>If there happens to be a blocking call, itâ€™ll block the execution of the other parts of the system that depend on the same commonPool. Hence, in general, itâ€™s better to have a separate executor/thread pool passed to our CompletableFuture implementation if the requirement involves any form of blocking I/O.</p>
<p>This <a href="https://dzone.com/articles/be-aware-of-forkjoinpoolcommonpool">blog</a> &amp; <a href="https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/concurrent/ForkJoinPool.html">the official documentation</a> further shares the common pitfalls of using the commonPool.</p>
<h2 id="using-a-custom-threadpoolexecutor">Using a Custom ThreadPoolExecutor</h2>
<p>ThreadPoolExecutors provide a means to execute tasks using the pooled threads. This not only reduces the overhead of creating new threads for each new submitted task, but also ensures that the resource utilization is not unbounded.</p>
<p>Instantiating the ThreadPoolExecutor requires setting the parameters appropriately; one should study the parameters such as core and maximum pool sizes, keepAliveTimes, workQueues &amp; tune them to their use case. Refer the <a href="https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/concurrent/ThreadPoolExecutor.html">JavaDocs - ThreadPoolExecutor</a> for understanding the meanings &amp; the defaults of the parameters. That said, itâ€™s urged to use the factory methods provided by the Executors class, a couple of them important ones are discussed below -</p>
<ul>
<li>
<p><a href="https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/concurrent/Executors.html#newWorkStealingPool()">newWorkStealingPool()</a> - Creates a work-stealing thread pool using the number of available processors as its target parallelism level. It may use multiple queues to reduce contention. It however, does not guarantee the order of execution in which the requests were submitted.</p>
</li>
<li>
<p><a href="https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/concurrent/Executors.html#newCachedThreadPool()">newCachedThreadPool()</a> - Creates a thread pool that creates new threads as needed, but will reuse previously constructed threads when they are available, and uses the provided ThreadFactory to create new threads when needed. It uses SynchronousQueue (a good default choice for a work queue) with â€‹â€‹unbounded maximumCorePoolSize. (ref: <a href="https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/concurrent/ThreadPoolExecutor.html">Direct Handoffs strategy of Queueing</a>)</p>
</li>
</ul>
<p>Besides the above two, one can create a <a href="https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/concurrent/Executors.html#newFixedThreadPool()">newFixedThreadPool()</a> (reuses a fixed number of threads operating on an unbounded shared workQueue), <a href="https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/concurrent/Executors.html#newSingleThreadExecutor()">newSingleThreadExecutor()</a> (single thread operating on an unbounded shared workQueue), <a href="https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/concurrent/Executors.html#newScheduledThreadPool()">newScheduledThreadPool()</a> (can be used to schedule tasks to run after a delay).</p>
<p>ðŸ’¡ As a matter of fact, gRPC, internally uses a CachedThreadPool by default for managing the app threads; It is in fact the default Thread Executor, reasons for the same are explained in the comment - <a href="https://github.com/grpc/grpc-java/issues/7381#issuecomment-684938279">https://github.com/grpc/grpc-java/issues/7381#issuecomment-684938279</a>.</p>
<h2 id="references">References</h2>
<ul>
<li><a href="https://www.infoq.com/articles/Functional-Style-Callbacks-Using-CompletableFuture/">https://www.infoq.com/articles/Functional-Style-Callbacks-Using-CompletableFuture/</a></li>
<li><a href="https://dzone.com/articles/be-aware-of-forkjoinpoolcommonpool">https://dzone.com/articles/be-aware-of-forkjoinpoolcommonpool</a></li>
<li><a href="https://dzone.com/articles/how-much-memory-does-a-java-thread-take">https://dzone.com/articles/how-much-memory-does-a-java-thread-take</a></li>
<li><a href="https://docs.oracle.com/javase/tutorial/essential/concurrency/pools.html">https://docs.oracle.com/javase/tutorial/essential/concurrency/pools.html</a></li>
<li><a href="https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/concurrent/ThreadPoolExecutor.html">https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/concurrent/ThreadPoolExecutor.html</a></li>
<li><a href="https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/concurrent/ForkJoinPool.html">https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/concurrent/ForkJoinPool.html</a></li>
<li><a href="https://www.baeldung.com/java-completablefuture">https://www.baeldung.com/java-completablefuture</a></li>
<li><a href="https://www.baeldung.com/java-fork-join#2-forkjoinpool-instantiation">https://www.baeldung.com/java-fork-join#2-forkjoinpool-instantiation</a></li>
</ul>
]]></content>
		</item>
		
		<item>
			<title>Essential Postgresql Queries</title>
			<link>https://shubhamutwal.in/posts/postgresql-commands/</link>
			<pubDate>Tue, 26 Mar 2019 23:13:20 +0530</pubDate>
			
			<guid>https://shubhamutwal.in/posts/postgresql-commands/</guid>
			<description>This post has a collated list of postgresql queries (taken from multiple sources) which are used on an almost daily basis.
 Age of unfrozen rows SELECT c.oid::regclass as table_name, greatest(age(c.relfrozenxid),age(t.relfrozenxid)) as age FROM pg_class c LEFT JOIN pg_class t ON c.reltoastrelid = t.oid WHERE c.relkind IN (&#39;r&#39;, &#39;m&#39;); SELECT datname, age(datfrozenxid) FROM pg_database; The age column measures the number of transactions from the cutoff XID to the current transaction&amp;rsquo;s XID.</description>
			<content type="html"><![CDATA[<p>This post has a collated list of postgresql queries (taken from multiple sources) which are used on an almost daily basis.</p>
<hr>
<h2 id="age-of-unfrozen-rows">Age of unfrozen rows</h2>
<pre><code class="language-psql" data-lang="psql">SELECT c.oid::regclass as table_name,
       greatest(age(c.relfrozenxid),age(t.relfrozenxid)) as age
FROM pg_class c
LEFT JOIN pg_class t ON c.reltoastrelid = t.oid
WHERE c.relkind IN ('r', 'm');
</code></pre><pre><code class="language-psql" data-lang="psql">SELECT datname, age(datfrozenxid) FROM pg_database;
</code></pre><p>The age column measures the number of transactions from the cutoff XID to the current transaction&rsquo;s XID. Here, the cutoff XID, <code>relfrozenxid</code> is the freeze cutoff XID that was used by the last whole-table VACUUM; likewise <code>datfrozenxid</code> is the lower bound on unfrozen XIDs for that database.</p>
<hr>
<h2 id="currently-running-queries">Currently running queries</h2>
<pre><code class="language-psql" data-lang="psql">SELECT pid, query, query_start FROM pg_stat_activity where state = 'active';
</code></pre><hr>
<h2 id="replication-status-on-masterslave">Replication Status on Master/Slave</h2>
<pre><code class="language-psql" data-lang="psql"># check replication/streaming status on MASTER
SELECT application_name,client_addr,state, \\
                 (sent_offset - (replay_offset - (sent_xlog - replay_xlog) * 255 * 16 ^ 6 ))::text AS byte_lag \\
                  FROM (SELECT \\
application_name,client_addr,state,sync_state,sent_lsn,write_lsn,replay_lsn, \\
                          ('x' || lpad(split_part(sent_lsn::text,   '/', 1), 8, '0'))::bit(32)::bigint AS sent_xlog, \\
                          ('x' || lpad(split_part(replay_lsn::text, '/', 1), 8, '0'))::bit(32)::bigint AS replay_xlog, \\
                          ('x' || lpad(split_part(sent_lsn::text,   '/', 2), 8, '0'))::bit(32)::bigint AS sent_offset, \\
                          ('x' || lpad(split_part(replay_lsn::text, '/', 2), 8, '0'))::bit(32)::bigint AS replay_offset \\
                        FROM pg_stat_replication) \\
                  AS s;

# check time elapsed since last replication on SLAVE
select now() - pg_last_xact_replay_timestamp() AS replication_delay;
</code></pre><hr>
<h2 id="time-when-autovacuum--autoanalyze-last-ran">Time when (auto)vacuum &amp; (auto)analyze last ran</h2>
<pre><code class="language-psql" data-lang="psql">select relname, last_vacuum, last_autovacuum, last_analyze, last_autoanalyze from pg_stat_user_tables;
</code></pre><hr>
<h2 id="number-of-live-tuples-and-dead-tuples">Number of live tuples and dead tuples</h2>
<pre><code class="language-psql" data-lang="psql">SELECT pg_stat_get_live_tuples(c.oid) AS n_live_tup, pg_stat_get_dead_tuples(c.oid) AS n_dead_tup FROM pg_class c where c.relname = '&lt;relname&gt;';
</code></pre>]]></content>
		</item>
		
		<item>
			<title>IN/Clojure 2019</title>
			<link>https://shubhamutwal.in/posts/in-clojure-2019/</link>
			<pubDate>Sat, 19 Jan 2019 23:26:56 +0530</pubDate>
			
			<guid>https://shubhamutwal.in/posts/in-clojure-2019/</guid>
			<description>Recently, I attended the ((((IN/Clojure)))) workshop which took place in Bangalore. The workshop was designed for two levels, a beginner &amp;amp; an intermediate one. Since, I had some previous knowledge around clojure, I signed up for the intermediate workshop.
The day of the workshop, we were expected to be ready with our own crazy setup, as long as it worked. Since, we are on the this, one could have a working clojure environment setup in Vim, Visual Studio Code, Sublime Text, Emacs, Spacemacs, IntelliJ (with Cursive) and what not.</description>
			<content type="html"><![CDATA[<p>Recently, I attended the <a href="https://inclojure.org/">((((IN/Clojure))))</a> workshop which took place in Bangalore. The workshop was designed for two levels, a beginner &amp; an intermediate one. Since, I had some previous knowledge around clojure, I signed up for the intermediate workshop.</p>
<p>The day of the workshop, we were expected to be ready with our own crazy setup, as long as it worked. Since, we are on the this, one could have a working clojure environment setup in <em>Vim, Visual Studio Code, Sublime Text, Emacs, Spacemacs, IntelliJ (with Cursive)</em> and what not. I now use Spacemacs having tried my hands on plain vanilla Emacs with certain tweaks <a href="https://github.com/darkdefender27/dotemacs">(dotfile for Emacs)</a>.</p>
<p>Every workshop/conference one has attended knows this well - it does not start without any wifi hassles. After overcoming those, we kickstarted with solving a basic problem of reading and processing data in a <em>.csv</em> file and then dumping the processed data in a database; and finally exposing a <em>GET</em> endpoint which reads &amp; omits out these records.</p>
<p>I got to replenish my stale knowledge on <em>Lazy Seq, Java Interop, REPL</em> interaction and of course <em>Spacemacs</em> shortcuts :p. The workshop further covered  concepts like Concurrency in Clojure, the motivation behind Clojure having immutable data structures, <em>Futures, Refs, Atoms, STMs,</em> a cool <code>Rock-Paper-Scissor</code> exercise demonstrating the above mentioned concepts.</p>
<p>The final segment of the workshop dealt with <code>core-async</code>. The same pattern was followed here as well, concepts and then exercises which worked-up those concepts. During this segment, I learnt how, using <em>core-async</em>, one can solve or scale the earlier problem of reading and processing data from a source, when your source is emitting out data in realtime (Streams!). To end the workshop, we solved the exercise, using <em>core-async&rsquo;s</em> channels; the exercise already had a base streaming solution in place with appropriate expressions to be filled in the blanks.</p>
<p>The content of the workshop had a good amount of variation, it went on from basics to intermediate to some advanced clojure at an appropriate pace. A well documented workshop material is made available on <a href="https://github.com/inclojure-org/intermediate-clojure-workshop/">Github</a>. So, just clone your way into the world of Fun Fun Functions!</p>
<hr>
<p><img src="../../images/lanyard_in_clojure_2019.jpg" alt="img"></p>
]]></content>
		</item>
		
		<item>
			<title>Apache Wsgi Configuration</title>
			<link>https://shubhamutwal.in/posts/apache-wsgi-configuration/</link>
			<pubDate>Sat, 17 Feb 2018 12:44:44 +0530</pubDate>
			
			<guid>https://shubhamutwal.in/posts/apache-wsgi-configuration/</guid>
			<description>TLDR; In this post I have put down my experience in configuring apache to interact with apps written in Python.
The bulk of this post is about how to set up Gunicorn as a WSGI HTTP Server to launch Python application(s) using the Flask micro-framework and Apache to act as a frontend reverse proxy.</description>
			<content type="html"><![CDATA[<p>TLDR; In this post I have put down my experience in configuring apache to interact with apps written in Python.</p>
<p>The bulk of this post is about how to set up Gunicorn as a WSGI HTTP Server to launch Python application(s) using the Flask micro-framework and Apache to act as a frontend reverse proxy.</p>
]]></content>
		</item>
		
	</channel>
</rss>
